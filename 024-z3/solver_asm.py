from z3 import *

def movsx(v):
  return ZeroExt(32 - 8, v)

def imul(a, b, c = None):
  if c is None:
    return a * b

  return b * c

def xor_(r, v):
  return r ^ v

def or_(r, v):
  return r | v

def mov(_, r2):
  return r2

def shr(r1, c):
  return LShR(r1, c)

def shl(r1, c):
  return r1 << c

def calc():
  esp_0x10 = BitVec("esp_0x10", 8)
  esp_0x11 = BitVec("esp_0x11", 8)  
  esp_0x12 = BitVec("esp_0x12", 8)  
  esp_0x13 = BitVec("esp_0x13", 8)  
  esp_0x14 = BitVec("esp_0x14", 8)  
  esp_0x15 = BitVec("esp_0x15", 8)  
  esp_0x16 = BitVec("esp_0x16", 8)  
  esp_0x17 = BitVec("esp_0x17", 8)  
  esp_0x18 = BitVec("esp_0x18", 8)
  esp_0x19 = BitVec("esp_0x19", 8)
  esp_0x1A = BitVec("esp_0x1A", 8)
  esp_0x1B = BitVec("esp_0x1B", 8)
  esp_0x1C = BitVec("esp_0x1C", 8)
  esp_0x1D = BitVec("esp_0x1D", 8)
  esp_0x1E = BitVec("esp_0x1E", 8)  
  esp_0x1F = BitVec("esp_0x1F", 8)    

  eax = BitVec("eax", 32)
  ebx = BitVec("ebx", 32)
  ecx = BitVec("ecx", 32)
  edx = BitVec("edx", 32)
  esi = BitVec("esi", 32)
  edi = BitVec("edi", 32)
  ebp = BitVec("ebp", 32)  

  edi = movsx(esp_0x10)
  edx = imul(edx, edi, 0x3039)
  edx = xor_(edx, 0x93E6BBCF)
  ebx = imul(ebx, edi, 0x0AEDCE)
  ebx = xor_(ebx, 0x2ECBBAE2)
  ecx = imul(ecx, edi, 0x2EF8F)
  ecx = xor_(ecx, 0x0A0A2A282)
  edi = imul(edi, 0x0DEDC7)
  edi = xor_(edi, 0x9BDFE6F7)
  eax = mov(eax, edx)
  eax = shr(eax, 3)
  edx = shl(edx, 3)
  eax = or_(eax, edx)
  edx = movsx(esp_0x11)
  esi = imul(esi, edx, 0x3039)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 5)
  ebx = shl(ebx, 5)
  esi = or_(esi, ebx)
  ebx = imul(ebx, edx, 0x0AEDCE)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 7)
  ecx = shl(ecx, 7)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, edx, 0x2EF8F)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edi)
  ecx = shr(ecx, 9)
  edi = shl(edi, 9)
  ecx = or_(ecx, edi)
  edx = imul(edx, 0x0DEDC7)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 3)
  eax = shl(eax, 3)
  edx = or_(edx, eax)
  edi = movsx(esp_0x12)
  eax = imul(eax, edi, 0x3039)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 5)
  esi = shl(esi, 5)
  eax = or_(eax, esi)
  esi = imul(esi, edi, 0x0AEDCE)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 7)
  ebx = shl(ebx, 7)
  esi = or_(esi, ebx)
  ebx = imul(ebx, edi, 0x2EF8F)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 9)
  ecx = shl(ecx, 9)
  ebx = or_(ebx, ecx)
  edi = imul(edi, 0x0DEDC7)
  ebx = xor_(ebx, edi)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 3)
  edx = shl(edx, 3)
  ecx = or_(ecx, edx)
  edi = movsx(esp_0x13)
  edx = imul(edx, edi, 0x3039)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 5)
  eax = shl(eax, 5)
  edx = or_(edx, eax)
  eax = imul(eax, edi, 0x0AEDCE)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 7)
  esi = shl(esi, 7)
  eax = or_(eax, esi)
  esi = imul(esi, edi, 0x2EF8F)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 9)
  ebx = shl(ebx, 9)
  esi = or_(esi, ebx)
  edi = imul(edi, 0x0DEDC7)
  esi = xor_(esi, edi)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 3)
  ecx = shl(ecx, 3)
  ebx = or_(ebx, ecx)
  edi = movsx(esp_0x14)
  ecx = imul(ecx, edi, 0x3039)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 5)
  edx = shl(edx, 5)
  ecx = or_(ecx, edx)
  edx = imul(edx, edi, 0x0AEDCE)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 7)
  eax = shl(eax, 7)
  edx = or_(edx, eax)
  eax = imul(eax, edi, 0x2EF8F)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 9)
  esi = shl(esi, 9)
  eax = or_(eax, esi)
  edi = imul(edi, 0x0DEDC7)
  eax = xor_(eax, edi)
  esi = mov(esi, ebx)
  esi = shr(esi, 3)
  ebx = shl(ebx, 3)
  esi = or_(esi, ebx)
  edi = movsx(esp_0x15)
  ebx = imul(ebx, edi, 0x3039)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 5)
  ecx = shl(ecx, 5)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, edi, 0x0AEDCE)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 7)
  edx = shl(edx, 7)
  ecx = or_(ecx, edx)
  edx = imul(edx, edi, 0x2EF8F)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 9)
  eax = shl(eax, 9)
  edx = or_(edx, eax)
  edi = imul(edi, 0x0DEDC7)
  edx = xor_(edx, edi)
  eax = mov(eax, esi)
  eax = shr(eax, 3)
  esi = shl(esi, 3)
  eax = or_(eax, esi)
  edi = movsx(esp_0x16)
  esi = imul(esi, edi, 0x3039)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 5)
  ebx = shl(ebx, 5)
  esi = or_(esi, ebx)
  ebx = imul(ebx, edi, 0x0AEDCE)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 7)
  ecx = shl(ecx, 7)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, edi, 0x2EF8F)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 9)
  edx = shl(edx, 9)
  ecx = or_(ecx, edx)
  edi = imul(edi, 0x0DEDC7)
  ecx = xor_(ecx, edi)
  edx = mov(edx, eax)
  edx = shr(edx, 3)
  eax = shl(eax, 3)
  edx = or_(edx, eax)
  edi = movsx(esp_0x17)
  eax = imul(eax, edi, 0x3039)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 5)
  esi = shl(esi, 5)
  eax = or_(eax, esi)
  esi = imul(esi, edi, 0x0AEDCE)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 7)
  ebx = shl(ebx, 7)
  esi = or_(esi, ebx)
  ebx = imul(ebx, edi, 0x2EF8F)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 9)
  ecx = shl(ecx, 9)
  ebx = or_(ebx, ecx)
  edi = imul(edi, 0x0DEDC7)
  ebx = xor_(ebx, edi)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 3)
  edx = shl(edx, 3)
  ecx = or_(ecx, edx)
  edi = movsx(esp_0x18)
  edx = imul(edx, edi, 0x3039)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 5)
  eax = shl(eax, 5)
  edx = or_(edx, eax)
  eax = imul(eax, edi, 0x0AEDCE)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 7)
  esi = shl(esi, 7)
  eax = or_(eax, esi)
  esi = imul(esi, edi, 0x2EF8F)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 9)
  ebx = shl(ebx, 9)
  esi = or_(esi, ebx)
  edi = imul(edi, 0x0DEDC7)
  esi = xor_(esi, edi)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 3)
  ecx = shl(ecx, 3)
  ebx = or_(ebx, ecx)
  edi = movsx(esp_0x19)
  ecx = imul(ecx, edi, 0x3039)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 5)
  edx = shl(edx, 5)
  ecx = or_(ecx, edx)
  edx = imul(edx, edi, 0x0AEDCE)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 7)
  eax = shl(eax, 7)
  edx = or_(edx, eax)
  eax = imul(eax, edi, 0x2EF8F)
  edx = xor_(edx, eax)
  eax = mov(eax, esi)
  eax = shr(eax, 9)
  esi = shl(esi, 9)
  eax = or_(eax, esi)
  edi = imul(edi, 0x0DEDC7)
  eax = xor_(eax, edi)
  esi = mov(esi, ebx)
  esi = shr(esi, 3)
  ebx = shl(ebx, 3)
  esi = or_(esi, ebx)
  edi = movsx(esp_0x1A)
  ebx = imul(ebx, edi, 0x3039)
  esi = xor_(esi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 5)
  ecx = shl(ecx, 5)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, edi, 0x0AEDCE)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 7)
  edx = shl(edx, 7)
  ecx = or_(ecx, edx)
  edx = imul(edx, edi, 0x2EF8F)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 9)
  eax = shl(eax, 9)
  edx = or_(edx, eax)
  edi = imul(edi, 0x0DEDC7)
  edx = xor_(edx, edi)
  eax = mov(eax, esi)
  eax = shr(eax, 3)
  esi = shl(esi, 3)
  eax = or_(eax, esi)
  esi = movsx(esp_0x1B)
  edi = imul(edi, esi, 0x3039)
  eax = xor_(eax, edi)
  edi = mov(edi, ebx)
  edi = shr(edi, 5)
  ebx = shl(ebx, 5)
  edi = or_(edi, ebx)
  ebx = imul(ebx, esi, 0x0AEDCE)
  edi = xor_(edi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 7)
  ecx = shl(ecx, 7)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, esi, 0x2EF8F)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 9)
  edx = shl(edx, 9)
  ecx = or_(ecx, edx)
  esi = imul(esi, 0x0DEDC7)
  ecx = xor_(ecx, esi)
  edx = mov(edx, eax)
  edx = shr(edx, 3)
  eax = shl(eax, 3)
  edx = or_(edx, eax)
  esi = movsx(esp_0x1C)
  eax = imul(eax, esi, 0x3039)
  edx = xor_(edx, eax)
  eax = mov(eax, edi)
  eax = shr(eax, 5)
  edi = shl(edi, 5)
  eax = or_(eax, edi)
  edi = imul(edi, esi, 0x0AEDCE)
  eax = xor_(eax, edi)
  edi = mov(edi, ebx)
  edi = shr(edi, 7)
  ebx = shl(ebx, 7)
  edi = or_(edi, ebx)
  ebx = imul(ebx, esi, 0x2EF8F)
  edi = xor_(edi, ebx)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 9)
  ecx = shl(ecx, 9)
  ebx = or_(ebx, ecx)
  esi = imul(esi, 0x0DEDC7)
  ebx = xor_(ebx, esi)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 3)
  edx = shl(edx, 3)
  ecx = or_(ecx, edx)
  esi = movsx(esp_0x1D)
  edx = imul(edx, esi, 0x3039)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 5)
  eax = shl(eax, 5)
  edx = or_(edx, eax)
  eax = imul(eax, esi, 0x0AEDCE)
  edx = xor_(edx, eax)
  eax = mov(eax, edi)
  eax = shr(eax, 7)
  edi = shl(edi, 7)
  eax = or_(eax, edi)
  edi = imul(edi, esi, 0x2EF8F)
  eax = xor_(eax, edi)
  edi = mov(edi, ebx)
  edi = shr(edi, 9)
  ebx = shl(ebx, 9)
  edi = or_(edi, ebx)
  esi = imul(esi, 0x0DEDC7)
  edi = xor_(edi, esi)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 3)
  ecx = shl(ecx, 3)
  ebx = or_(ebx, ecx)
  esi = movsx(esp_0x1E)
  ecx = imul(ecx, esi, 0x3039)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 5)
  edx = shl(edx, 5)
  ecx = or_(ecx, edx)
  edx = imul(edx, esi, 0x0AEDCE)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 7)
  eax = shl(eax, 7)
  edx = or_(edx, eax)
  eax = imul(eax, esi, 0x2EF8F)
  edx = xor_(edx, eax)
  eax = mov(eax, edi)
  eax = shr(eax, 9)
  edi = shl(edi, 9)
  eax = or_(eax, edi)
  esi = imul(esi, 0x0DEDC7)
  eax = xor_(eax, esi)
  esi = mov(esi, ebx)
  esi = shr(esi, 3)
  ebx = shl(ebx, 3)
  esi = or_(esi, ebx)
  edi = movsx(esp_0x1F)
  ebx = mov(ebx, ecx)
  ebx = shr(ebx, 5)
  ecx = shl(ecx, 5)
  ebx = or_(ebx, ecx)
  ecx = imul(ecx, edi, 0x0AEDCE)
  ebx = xor_(ebx, ecx)
  ecx = mov(ecx, edx)
  ecx = shr(ecx, 7)
  edx = shl(edx, 7)
  ecx = or_(ecx, edx)
  edx = imul(edx, edi, 0x2EF8F)
  ecx = xor_(ecx, edx)
  edx = mov(edx, eax)
  edx = shr(edx, 9)
  eax = shl(eax, 9)
  edx = or_(edx, eax)
  eax = imul(eax, edi, 0x0DEDC7)
  edx = xor_(edx, eax)
  edi = imul(edi, 0x3039)
  esi = xor_(esi, edi)

  #print esi
  #return

  #print simplify(esi)

  s = Solver()
  s.add(esi == 0xFFF4A1CE)
  s.add(ebx == 0xB5A4A9A7)
  s.add(ecx == 0xF05A945C)
  s.add(edx == 0x9504A82D)
  s.add(esp_0x10 >= 32, esp_0x10 <= 126)
  s.add(esp_0x11 >= 32, esp_0x11 <= 126)
  s.add(esp_0x12 >= 32, esp_0x12 <= 126)
  s.add(esp_0x13 >= 32, esp_0x13 <= 126)
  s.add(esp_0x14 >= 32, esp_0x14 <= 126)
  s.add(esp_0x15 >= 32, esp_0x15 <= 126)
  s.add(esp_0x16 >= 32, esp_0x16 <= 126)
  s.add(esp_0x17 >= 32, esp_0x17 <= 126)
  s.add(esp_0x18 >= 32, esp_0x18 <= 126)
  s.add(esp_0x19 >= 32, esp_0x19 <= 126)
  s.add(esp_0x1A >= 32, esp_0x1A <= 126)
  s.add(esp_0x1B >= 32, esp_0x1B <= 126)
  s.add(esp_0x1C >= 32, esp_0x1C <= 126)
  s.add(esp_0x1D >= 32, esp_0x1D <= 126)
  s.add(esp_0x1E >= 32, esp_0x1E <= 126)
  s.add(esp_0x1F >= 32, esp_0x1F <= 126)  
  s.check()
  print s.model()


calc()

